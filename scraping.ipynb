{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from time import time, sleep\n",
    "from selenium import webdriver\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "from work.rap_machine_genius_code import read_pickle, write_pickle, Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Song data structure that will store info about each song.\n",
    "# Remember: namedtuples require that you fill in each field.\n",
    "\n",
    "Song = namedtuple('Song', ['header', 'verified', 'metadata', 'lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_driver(url):\n",
    "    \"\"\"This function will open a Chrome browser at the given url.\n",
    "    Args: \n",
    "      url (string): a valid URL as a string.\n",
    "    Returns:\n",
    "      None\n",
    "\n",
    "    Doesn't return anything, but creates a global variable *driver*\n",
    "    that can be called upon elsewhere.\"\"\"\n",
    "\n",
    "    # path to the chromedriver executable\n",
    "\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "    # Using the global keyword so that we can call upon the driver\n",
    "    # further down in the code.\n",
    "\n",
    "    global driver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start by opening the all rap songs page.\n",
    "# I might spend some time exploring the architecture of Genius.com\n",
    "# to identify other places to grab song links.\n",
    "\n",
    "all_rap_songs_genius = \"https://genius.com/tags/rap/all\"\n",
    "start_driver(all_rap_songs_genius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Selenium to scroll down to the bottom of the screen\n",
    "# Be sure to click on the Chrome browser to give it focus.\n",
    "# You may have to run this cell a couple times \n",
    "# before it gets you all the way to the bottom of the screen\n",
    "\n",
    "for _ in range (60):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet is there to grab links to songs\n",
    "# on the https://genius.com/tags/rap/all page.\n",
    "# It appears that 1000 is the most search results\n",
    "# that genius.com will display at one time.\n",
    "\n",
    "\n",
    "link_selector = '//a[@class= \" song_link\"]'\n",
    "top_songs = driver.find_elements_by_xpath(link_selector)\n",
    "\n",
    "\n",
    "link_list = []\n",
    "\n",
    "for elem in top_songs:\n",
    "    link_list.append(elem.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling aborted because data/links.pkl is already a file.\n"
     ]
    }
   ],
   "source": [
    "# I save the list of links as a pickle.\n",
    "# That way, I don't have to do this again.\n",
    "\n",
    "write_pickle(link_list, 'data/links.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I pick up again I can just pull from the pickle\n",
    "\n",
    "link_list = read_pickle('data/links.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info(list_of_urls):\n",
    "    \n",
    "    \"\"\"This function uses the Chrome driver to visit \n",
    "    every page on a list of Genius links,\n",
    "    and gathers the info I want to analyze.\n",
    "    Warning: this function can take an hour to run,\n",
    "    because it pauses on each page to avoid getting your IP banned.\n",
    "    \n",
    "    Args:\n",
    "      list_of_urls:\n",
    "        a list of strings. Must be links on Genius.com\n",
    "        otherwise it won't work. \n",
    "        \n",
    "    Returns:\n",
    "      dict_of_songs:\n",
    "        a dictionary where each key is a url to a Genius page\n",
    "        for a given song, and the value is a namedtuple\n",
    "        of the Song format (defined at the top of this notebook).\"\"\"\n",
    "\n",
    "    dict_of_songs = defaultdict(Song)\n",
    "\n",
    "    for i, url in enumerate(list_of_urls):\n",
    "        driver.get(url)\n",
    "        driver.execute_script(\n",
    "            \"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(.5+2*random.random())\n",
    "\n",
    "        # Gather and filter metadata\n",
    "\n",
    "        views_regex = re.compile('views', re.IGNORECASE)\n",
    "        contrib_regex = re.compile('contributors', re.IGNORECASE)\n",
    "        tag_regex = re.compile('(\\w+,\\s\\w+)+')\n",
    "\n",
    "        all_metadata = driver.find_elements_by_class_name('metadata_with_icon')\n",
    "\n",
    "        filtered_metadata = [metadata.text for metadata in all_metadata\n",
    "                             if re.search(views_regex, metadata.text)\n",
    "                             or re.search(contrib_regex, metadata.text)\n",
    "                             or re.search(tag_regex, metadata.text)]\n",
    "\n",
    "        # Scrape raw lyrics\n",
    "\n",
    "        lyrics_string = ''\n",
    "\n",
    "        lyrics = driver.find_elements_by_class_name('song_body-lyrics')\n",
    "        for lyric in lyrics:\n",
    "            lyrics_string += lyric.text\n",
    "\n",
    "        # Scrape header\n",
    "\n",
    "        header_string = driver.find_element_by_class_name(\n",
    "            'header_with_cover_art-primary_info').text\n",
    "\n",
    "        # Determine whether artist has contributed to their song page\n",
    "\n",
    "        try:\n",
    "            ver_art = driver.find_element_by_class_name(\n",
    "                'song_verified_artists-section')\n",
    "            verified_bool = True\n",
    "        except:\n",
    "            verified_bool = False\n",
    "            \n",
    "        # Create Song named tuple and add to dictionary\n",
    "\n",
    "        dict_of_songs[url] = Song(header=header_string, lyrics=lyrics_string,\n",
    "                                  verified=verified_bool, metadata=filtered_metadata)\n",
    "        if (i+1 % 100 == 0):\n",
    "            time.sleep(320)\n",
    "\n",
    "    return dict_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get it to visit each link in the list!\n",
    "# Careful--this may take hours!\n",
    "song_dict = scrape_info(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling aborted because data/songs_dict.pkl is already a file.\n"
     ]
    }
   ],
   "source": [
    "write_pickle(song_dict, 'data/songs_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_dict = read_pickle('data/songs_dict.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
